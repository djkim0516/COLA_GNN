{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "from torch.nn import Parameter\r\n",
    "import torch.nn.functional as F\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\r\n",
    "\r\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "num_nodes = 10\r\n",
    "\r\n",
    "train_rate = 0.5\r\n",
    "seq_len = 20\r\n",
    "output_dim = pred_len = 10\r\n",
    "batch_size = 32\r\n",
    "lr = 0.001\r\n",
    "training_epoch = 1001\r\n",
    "validation_rate = 0.1\r\n",
    "l2_coeff = 0.0001\r\n",
    "\r\n",
    "\r\n",
    "#for ILI Region data\r\n",
    "adj_pearson = pd.read_csv('input_data/Region_adj_geo1.csv', header=None)\r\n",
    "adj = np.mat(adj_pearson)\r\n",
    "\r\n",
    "#region features(data)\r\n",
    "data = pd.read_csv('input_data/ILI_region_feature_1997-2020.csv')\r\n",
    "data = np.mat(data, dtype=np.float32)\r\n",
    "\r\n",
    "scaler = MinMaxScaler()\r\n",
    "scaler.fit(data[0:int(len(data)/2)])   #절반까지(train data)에 대해서만 fit\r\n",
    "data = scaler.transform(data)\r\n",
    "\r\n",
    "print(data[-5:])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.82012    3.1085544  1.6115223  0.6289664  0.4157108  0.7908482\n",
      "  0.28640518 0.37363324 0.31908202 2.917647  ]\n",
      " [1.3491006  1.869935   1.2565175  0.44287363 0.33733055 0.5245536\n",
      "  0.18484686 0.25835678 0.23137377 2.1294117 ]\n",
      " [1.254497   1.1125563  1.0218861  0.33155304 0.28832117 0.38214287\n",
      "  0.13272434 0.17213371 0.18170387 1.4282353 ]\n",
      " [0.8554297  0.6910956  0.96202123 0.2925961  0.287626   0.3502232\n",
      "  0.13057497 0.16526085 0.1615844  1.435294  ]\n",
      " [0.68820786 0.48724365 0.8052784  0.2448424  0.2716371  0.28191966\n",
      "  0.1144546  0.12527335 0.14806664 1.2917646 ]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "device, torch.cuda.get_device_name()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0), 'NVIDIA GeForce RTX 2080 SUPER')"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "time_len =data.shape[0]     #총 시간\r\n",
    "num_nodes = data.shape[1]   #지역 node 갯수\r\n",
    "print(time_len, num_nodes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1179 10\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "def preprocess_data(data, time_len, train_rate, validation_rate, seq_len, pred_len):\r\n",
    "    \"\"\"\r\n",
    "    하나의 node에 대해서 seq_len=20 짜리의 데이터를 취한 것을, \r\n",
    "    모든 node=10 에 대해서 쌓아서, \r\n",
    "    하나의 time_step에 대한 data를 만들고,\r\n",
    "    모든 time_step에 대해서 쌓은 크기\r\n",
    "    의 data를 floattensor로 반환하는 함수\r\n",
    "    \"\"\"\r\n",
    "    train_size = int(time_len * train_rate)\r\n",
    "    validation_size = int(time_len * validation_rate)\r\n",
    "    print(f\"train_size : {train_size}, validation_size : {validation_size}\")\r\n",
    "    train_data = data[0:train_size]\r\n",
    "    print(f\"train_data shape : {train_data.shape}\")\r\n",
    "    validation_data = data[train_size - seq_len : train_size + validation_size] #train data 바로 다음 시점부터 validation 시작\r\n",
    "    test_data = data[train_size + validation_size - seq_len : time_len]\r\n",
    "    print(f\"test_data shape : {test_data.shape}\")\r\n",
    "    \r\n",
    "    X_train, y_train, X_test, y_test = [], [], [], []\r\n",
    "    \r\n",
    "    for i in range(len(train_data) - seq_len - pred_len):\r\n",
    "        \r\n",
    "        temp = train_data[i:i + seq_len + pred_len]\r\n",
    "        \r\n",
    "        X_train.append(np.transpose(temp[:seq_len]))    #여기선 transpose인데\r\n",
    "        y_train.append(temp[seq_len + pred_len - 1])    #여기선 왜 단일 값? -> \r\n",
    "        \r\n",
    "    for i in range(len(test_data) - seq_len - pred_len):\r\n",
    "        \r\n",
    "        temp = test_data[i:i + seq_len + pred_len]\r\n",
    "        \r\n",
    "        X_test.append(np.transpose(temp[:seq_len]))\r\n",
    "        y_test.append(temp[seq_len + pred_len - 1])\r\n",
    "        \r\n",
    "    X_train = np.array(X_train)\r\n",
    "    y_train = np.array(y_train)\r\n",
    "    X_test = np.array(X_test)\r\n",
    "    y_test = np.array(y_test)\r\n",
    "    \r\n",
    "    print(f\"\\nX_train : {X_train.shape} | y_train : {y_train.shape} \\nX_test : {X_test.shape} | y_test : {y_test.shape}\")\r\n",
    "    \r\n",
    "    return torch.FloatTensor(X_train).to(device), torch.FloatTensor(y_train).to(device), torch.FloatTensor(X_test).to(device), torch.FloatTensor(y_test).to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "X_train, y_train, X_test, y_test = preprocess_data(data, time_len, train_rate, validation_rate, seq_len, pred_len)\r\n",
    "#print(X_train.dtype, y_train.dtype)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_size : 589, validation_size : 117\n",
      "train_data shape : (589, 10)\n",
      "test_data shape : (493, 10)\n",
      "\n",
      "X_train : (559, 10, 20) | y_train : (559, 10) \n",
      "X_test : (463, 10, 20) | y_test : (463, 10)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "training_data_count = len(X_train)\r\n",
    "print(training_data_count, X_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "559 (559, 10, 20)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "train = torch.utils.data.TensorDataset(X_train, y_train)\r\n",
    "test = torch.utils.data.TensorDataset(X_test, y_test)\r\n",
    "\r\n",
    "trainloader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\r\n",
    "testloader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "rnn_hidden_size = 12    #for dim check 12\r\n",
    "rnn_num_layers = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "'''\r\n",
    "#model 앞부분에 node별로 temporal dependency를 추출하기 위한 RNN\r\n",
    "\r\n",
    "class RNN(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self, input_size, hidden_size, sequence_length, num_layers, device):\r\n",
    "        super().__init__()\r\n",
    "        self.device = device\r\n",
    "        self.input_size = input_size\r\n",
    "        self.hidden_size = hidden_size\r\n",
    "        self.num_layers = num_layers\r\n",
    "        self.rnn = nn.RNN(input_size = self.input_size, hidden_size = self.hidden_size, num_layers = self.num_layers, batch_first = True)\r\n",
    "        #여기서는 RNN output을 그대로 사용할 것 이기 때문에 마지막 sequential layer가 필요 없을 것 으로 생각\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        h0 = torch.zeros(self.num_layers, x.size()[0], self.hidden_size).to(self.device)      #나중에 node 별로 모델 새로 선언 필요\r\n",
    "        #initial hidden state 여기서는 zeros, 나중에는 normalized values 시도 | x.size()[0] == batch_size, hidden_size 정해줘야함\r\n",
    "        _, h0 = self.rnn(x, h0)       #***우리는 여기서 hidden_state가 필요함! 나중에 모든 node에 대해서 hidden_state들을 쌓아야됨***\r\n",
    "        #문제는, 여기서의 output값이 필요한지는 확실치 않음 - 이 RNN으로 값을 예측하려는 것이 아니기 때문, 아마 hidden 만 쓸 것으로 생각\r\n",
    "        \r\n",
    "        return h0\r\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "\r\n",
    "\r\n",
    "#model 앞부분에 node별로 temporal dependency를 추출하기 위한 RNN\r\n",
    "\r\n",
    "class cola_gnn(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self, input_size, rnn_hidden_size, sequence_length, rnn_num_layers, conv_channel_num=8, device=device):\r\n",
    "        super().__init__()\r\n",
    "        self.device = device            #cuda else cpu\r\n",
    "        self.input_size = input_size    #10(node)*20(seq_length) tensor\r\n",
    "        self.rnn_hidden_size = rnn_hidden_size\r\n",
    "        self.sequence_length = sequence_length  #seq_length\r\n",
    "        self.rnn_num_layers = rnn_num_layers    #\r\n",
    "        self.conv_channel_num = conv_channel_num\r\n",
    "        self.RNN_modules = {\r\n",
    "            'RNN_0' : nn.RNN(input_size = self.sequence_length, hidden_size = self.rnn_hidden_size, num_layers = self.rnn_num_layers, batch_first = True, nonlinearity = 'tanh', device=self.device),\r\n",
    "            'RNN_1' : nn.RNN(input_size = self.sequence_length, hidden_size = self.rnn_hidden_size, num_layers = self.rnn_num_layers, batch_first = True, nonlinearity = 'tanh', device=self.device),\r\n",
    "            'RNN_2' : nn.RNN(input_size = self.sequence_length, hidden_size = self.rnn_hidden_size, num_layers = self.rnn_num_layers, batch_first = True, nonlinearity = 'tanh', device=self.device),\r\n",
    "            'RNN_3' : nn.RNN(input_size = self.sequence_length, hidden_size = self.rnn_hidden_size, num_layers = self.rnn_num_layers, batch_first = True, nonlinearity = 'tanh', device=self.device),\r\n",
    "            'RNN_4' : nn.RNN(input_size = self.sequence_length, hidden_size = self.rnn_hidden_size, num_layers = self.rnn_num_layers, batch_first = True, nonlinearity = 'tanh', device=self.device),\r\n",
    "            'RNN_5' : nn.RNN(input_size = self.sequence_length, hidden_size = self.rnn_hidden_size, num_layers = self.rnn_num_layers, batch_first = True, nonlinearity = 'tanh', device=self.device),\r\n",
    "            'RNN_6' : nn.RNN(input_size = self.sequence_length, hidden_size = self.rnn_hidden_size, num_layers = self.rnn_num_layers, batch_first = True, nonlinearity = 'tanh', device=self.device),\r\n",
    "            'RNN_7' : nn.RNN(input_size = self.sequence_length, hidden_size = self.rnn_hidden_size, num_layers = self.rnn_num_layers, batch_first = True, nonlinearity = 'tanh', device=self.device),\r\n",
    "            'RNN_8' : nn.RNN(input_size = self.sequence_length, hidden_size = self.rnn_hidden_size, num_layers = self.rnn_num_layers, batch_first = True, nonlinearity = 'tanh', device=self.device),\r\n",
    "            'RNN_9' : nn.RNN(input_size = self.sequence_length, hidden_size = self.rnn_hidden_size, num_layers = self.rnn_num_layers, batch_first = True, nonlinearity = 'tanh', device=self.device)  \r\n",
    "        }\r\n",
    "        \r\n",
    "        self.Dil_Conv_short_modules = {\r\n",
    "            'Dil_Conv_0' : nn.Conv1d(1, self.conv_channel_num, self.sequence_length, device=self.device),\r\n",
    "            'Dil_Conv_1' : nn.Conv1d(1, self.conv_channel_num, self.sequence_length, device=self.device),\r\n",
    "            'Dil_Conv_2' : nn.Conv1d(1, self.conv_channel_num, self.sequence_length, device=self.device),\r\n",
    "            'Dil_Conv_3' : nn.Conv1d(1, self.conv_channel_num, self.sequence_length, device=self.device),\r\n",
    "            'Dil_Conv_4' : nn.Conv1d(1, self.conv_channel_num, self.sequence_length, device=self.device),\r\n",
    "            'Dil_Conv_5' : nn.Conv1d(1, self.conv_channel_num, self.sequence_length, device=self.device),\r\n",
    "            'Dil_Conv_6' : nn.Conv1d(1, self.conv_channel_num, self.sequence_length, device=self.device),\r\n",
    "            'Dil_Conv_7' : nn.Conv1d(1, self.conv_channel_num, self.sequence_length, device=self.device),\r\n",
    "            'Dil_Conv_8' : nn.Conv1d(1, self.conv_channel_num, self.sequence_length, device=self.device),\r\n",
    "            'Dil_Conv_9' : nn.Conv1d(1, self.conv_channel_num, self.sequence_length, device=self.device)\r\n",
    "            #'Dil_Conv_long' : nn.Conv1d(1, self.conv_channel_num, self.sequence_length - self.input_size, dilation=2)\r\n",
    "        }\r\n",
    "        self.Dil_Conv_long_modules = {\r\n",
    "            #'Dil_Conv_short' : nn.Conv1d(1, self.conv_channel_num, self.sequence_length),\r\n",
    "            'Dil_Conv_0' : nn.Conv1d(1, self.conv_channel_num, int(self.sequence_length/2), dilation=2, device=self.device),\r\n",
    "            'Dil_Conv_1' : nn.Conv1d(1, self.conv_channel_num, int(self.sequence_length/2), dilation=2, device=self.device),\r\n",
    "            'Dil_Conv_2' : nn.Conv1d(1, self.conv_channel_num, int(self.sequence_length/2), dilation=2, device=self.device),\r\n",
    "            'Dil_Conv_3' : nn.Conv1d(1, self.conv_channel_num, int(self.sequence_length/2), dilation=2, device=self.device),\r\n",
    "            'Dil_Conv_4' : nn.Conv1d(1, self.conv_channel_num, int(self.sequence_length/2), dilation=2, device=self.device),\r\n",
    "            'Dil_Conv_5' : nn.Conv1d(1, self.conv_channel_num, int(self.sequence_length/2), dilation=2, device=self.device),\r\n",
    "            'Dil_Conv_6' : nn.Conv1d(1, self.conv_channel_num, int(self.sequence_length/2), dilation=2, device=self.device),\r\n",
    "            'Dil_Conv_7' : nn.Conv1d(1, self.conv_channel_num, int(self.sequence_length/2), dilation=2, device=self.device),\r\n",
    "            'Dil_Conv_8' : nn.Conv1d(1, self.conv_channel_num, int(self.sequence_length/2), dilation=2, device=self.device),\r\n",
    "            'Dil_Conv_9' : nn.Conv1d(1, self.conv_channel_num, int(self.sequence_length/2), dilation=2, device=self.device)\r\n",
    "        }\r\n",
    "        #여기 지금 길이 (8,2)라는데 수정필요함!!!!!!!!!!!!!\r\n",
    "        \r\n",
    "        #여기서는 RNN hidden state를 그대로 사용할 것 이기 때문에 마지막 sequential layer가 필요 없음\r\n",
    "        \r\n",
    "        \r\n",
    "        #RNN 선언하고\r\n",
    "        #~Dilated Conv 선언하고\r\n",
    "        #Loc-Aware-Attn Matrix 만들고\r\n",
    "        #graph message passing 하고\r\n",
    "        #output layer 제작하고\r\n",
    "        #backprop은 나중에 최적화\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        '''\r\n",
    "        ***WRONG DESCRIPTION***\r\n",
    "        h_RNN_0 = torch.zeros(self.rnn_num_layers, x.size()[0], self.rnn_hidden_size).to(self.device)      #나중에 node 별로 모델 새로 선언 필요\r\n",
    "        #initial hidden state 여기서는 zeros, 나중에는 normalized values 시도 | x.size()[0] == batch_size, rnn_hidden_size 정해줘야함\r\n",
    "        _, h_RNN_0 = self.rnn(x, h_RNN_0)       #***우리는 여기서 hidden_state가 필요함! 나중에 모든 node에 대해서 hidden_state들을 쌓아야됨***\r\n",
    "        #문제는, 여기서의 output값이 필요한지는 확실치 않음 - 이 RNN으로 값을 예측하려는 것이 아니기 때문, 아마 hidden 만 쓸 것으로 생각\r\n",
    "        '''\r\n",
    "        RNN_hidden_concat = torch.zeros(self.input_size[0], self.rnn_hidden_size).to(self.device)   #10(num_node)*12(num_hidden)\r\n",
    "        Conv_hidden_concat = torch.zeros(self.input_size[0], self.conv_channel_num, 2*self.sequence_length - self.input_size[0]).to(self.device)\r\n",
    "        \r\n",
    "        #여기에 batch 에 따른 iter 필요???\r\n",
    "        for batch in range(len(x)):\r\n",
    "            x = x[batch]            #batch 하나 가져오기\r\n",
    "            \r\n",
    "            for i in range(len(self.RNN_modules)):  \r\n",
    "                print(x.size())\r\n",
    "                single_seq = x[i].reshape([1, 1, self.sequence_length])   #batch 1개 * node 1개 * seq_len // batch 하나에서 RNN을 각각 어떻게 train?\r\n",
    "                print(single_seq.size())\r\n",
    "                \r\n",
    "                #RNN part\r\n",
    "                rnn_out_i, _ = self.RNN_modules[f'RNN_{i}'](single_seq)       #RNNs training, activation needed\r\n",
    "                RNN_hidden_concat[i] = rnn_out_i       #for future loc-aware-attn? 이렇게 저장하면 안될듯, 나중에 RNN 호출하는걸로\r\n",
    "            \r\n",
    "                #Dilated Conv part\r\n",
    "                conv_out_short_i = self.Dil_Conv_short_modules[f'Dil_Conv_{i}'](single_seq)\r\n",
    "                conv_out_long_i = self.Dil_Conv_long_modules[f'Dil_Conv_{i}'](single_seq)\r\n",
    "                Conv_hidden_concat[i, :self.sequence_length] = conv_out_short_i\r\n",
    "                Conv_hidden_concat[i, self.sequence_length:] = conv_out_long_i\r\n",
    "                \r\n",
    "                Conv_hidden_concat = torch.relu(Conv_hidden_concat)\r\n",
    "\r\n",
    "        \r\n",
    "        \r\n",
    "        \r\n",
    "        return Conv_hidden_concat\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "2 8\n",
      "2 9\n",
      "2 10\n",
      "2 11\n",
      "2 12\n",
      "2 13\n",
      "2 14\n",
      "2 15\n",
      "2 16\n",
      "2 17\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = torch.tensor([[[1,2,3,4],[5,6,7,8],[9,10,11,12]]]) #.reshape([1,4])\r\n",
    "b = torch.tensor([[[21,22,23,24],[25,26,27,28],[29,30,31,32]]])\r\n",
    "#c = torch.stack((a,b), dim=0)\r\n",
    "#c = torch.vstack((a, b))\r\n",
    "#c = torch.vstack((c, b))\r\n",
    "#c\r\n",
    "torch.vstack((a,b)).size()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rnn_hidden_size, seq_len, rnn_num_layers, device"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Training Part\r\n",
    "model = cola_gnn(input_size=X_train.shape[1:],\r\n",
    "                 rnn_hidden_size=rnn_hidden_size,\r\n",
    "                 sequence_length=seq_len,\r\n",
    "                 rnn_num_layers=rnn_num_layers,\r\n",
    "                 device=device).to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss_graph = []\r\n",
    "n= len(trainloader)\r\n",
    "for epoch in range(1):\r\n",
    "    running_loss = 0.0\r\n",
    "    \r\n",
    "    for data in trainloader:\r\n",
    "        seq, target = data  #batch data\r\n",
    "        print(seq.size())\r\n",
    "        out = model(seq)\r\n",
    "        #loss = criterion(out, target)   #criterion def required\r\n",
    "        \r\n",
    "        #optimizer.zero_grad()           #optimizer def required\r\n",
    "        #loss.backward()\r\n",
    "        #optimizer.step()\r\n",
    "        #running_loss += loss.item()\r\n",
    "        \r\n",
    "        print(target)\r\n",
    "        \r\n",
    "    loss_graph.append(running_loss/n)\r\n",
    "    ###print, visualization etc.\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(model.input_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = {'rnn0':0, 'rnn1':1, 'rnn2':2}\r\n",
    "for i in range(len(test)):\r\n",
    "    print(test[f'rnn{i}'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#우선 RNN cell을 훈련\r\n",
    "num = 0\r\n",
    "for i in trainloader:\r\n",
    "    print(len(i[0]), num)\r\n",
    "    num += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "class cola_gnn(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self, ):\r\n",
    "        super().__init__()\r\n",
    "            "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "bdcbac5c9a1519ddd88a9886e2997c9832aa06defa284c5fffbc39a53f7c6e9b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}